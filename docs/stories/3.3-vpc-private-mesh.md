# Story 3.3: VPC Connector + Private Mesh Networking

## Status
Draft

## Story
**As a** security engineer
**I want** mesh services (users, agent, journal, etc.) accessible only via VPC (ingress: internal)
**So that** unauthorized public access is prevented; only gateway can reach mesh over VPC connector

## Acceptance Criteria

1. **VPC created (or use existing):** GCP VPC network exists for production environment
2. **VPC Connector provisioned:** Serverless VPC Access connector created in production region
3. **Mesh services set to internal:** All 7 mesh services (`users_service`, `agent_service`, `journal_service`, `habits_service`, `meals_service`, `movements_service`, `practices_service`) have `ingress = "internal"` (NOT publicly accessible)
4. **Gateway configured for VPC:** Gateway service configured to use VPC connector for outbound requests to mesh
5. **Gateway remains public:** Gateway service has `ingress = "all"` (publicly accessible via HTTPS)
6. **Service discovery updated:** Gateway mesh configuration updated with internal URLs for mesh services
7. **Firewall rules configured (if needed):** VPC firewall rules allow gateway → mesh communication
8. **Connectivity validated:** Manual testing confirms gateway can reach all mesh services over VPC, public internet cannot

## Tasks / Subtasks

- [ ] **Create or validate VPC** (AC: 1)
  - [ ] Check if production VPC already exists: `gcloud compute networks list`
  - [ ] If not exists, create VPC: `gcloud compute networks create mindmirror-prod-vpc --subnet-mode=auto`
  - [ ] Note VPC name for VPC connector configuration

- [ ] **Create VPC Connector** (AC: 2)
  - [ ] Define OpenTofu resource for VPC connector:
    ```hcl
    resource "google_vpc_access_connector" "production_connector" {
      name          = "mindmirror-prod-connector"
      region        = var.region  # e.g., "us-east1"
      network       = "mindmirror-prod-vpc"
      ip_cidr_range = "10.8.0.0/28"  # /28 = 16 IPs (minimum for connector)
      min_instances = 2  # Minimum for availability
      max_instances = 3  # Scale up if needed
    }
    ```
  - [ ] Add to `infra/main.tf` or dedicated `infra/networking.tf`
  - [ ] Run `tofu plan` and `tofu apply` to create connector
  - [ ] Validate connector created: `gcloud compute networks vpc-access connectors list`

- [ ] **Configure mesh services as internal** (AC: 3)
  - [ ] Update OpenTofu for each mesh service (`google_cloud_run_v2_service`):
    ```hcl
    resource "google_cloud_run_v2_service" "users_service" {
      # ... other config ...

      ingress = "INGRESS_TRAFFIC_INTERNAL_ONLY"  # NOT publicly accessible

      # ... rest of config ...
    }
    ```
  - [ ] Apply to all 7 mesh services:
    - `users_service` (CRITICAL - entire system depends on this)
    - `agent_service`
    - `journal_service`
    - `habits_service`
    - `meals_service`
    - `movements_service`
    - `practices_service`
  - [ ] Run `tofu plan` to review changes
  - [ ] **CRITICAL:** Backup OpenTofu state before applying
  - [ ] Run `tofu apply` to make services private

- [ ] **Configure gateway to use VPC connector** (AC: 4, 5)
  - [ ] Update gateway OpenTofu (`google_cloud_run_v2_service`):
    ```hcl
    resource "google_cloud_run_v2_service" "gateway" {
      # ... other config ...

      ingress = "INGRESS_TRAFFIC_ALL"  # Gateway remains PUBLIC

      template {
        # ... other template config ...

        vpc_access {
          connector = google_vpc_access_connector.production_connector.id
          egress    = "PRIVATE_RANGES_ONLY"  # Route only private IPs through VPC
        }
      }
    }
    ```
  - [ ] Run `tofu plan` and `tofu apply`
  - [ ] Validate gateway can still be accessed publicly: `curl https://[gateway-url]/healthcheck`

- [ ] **Update service discovery in gateway** (AC: 6)
  - [ ] Identify internal URLs for mesh services (format: `https://[service-name]-[hash]-[region].a.run.app`)
  - [ ] Update `mesh/mesh.config.dynamic.ts` or equivalent configuration:
    ```typescript
    const services = {
      users: process.env.USERS_SERVICE_URL || 'https://users-service-internal-xyz.a.run.app',
      agent: process.env.AGENT_SERVICE_URL || 'https://agent-service-internal-xyz.a.run.app',
      // ... other services
    };
    ```
  - [ ] Set environment variables in gateway Cloud Run service (via OpenTofu or Secret Manager)
  - [ ] Redeploy gateway with updated configuration

- [ ] **Configure firewall rules (if needed)** (AC: 7)
  - [ ] Check if VPC firewall rules are needed for Cloud Run → Cloud Run communication
  - [ ] If needed, create allow rule:
    ```hcl
    resource "google_compute_firewall" "allow_gateway_to_mesh" {
      name    = "allow-gateway-mesh"
      network = "mindmirror-prod-vpc"

      allow {
        protocol = "tcp"
        ports    = ["443", "8080"]  # HTTPS and common Cloud Run port
      }

      source_ranges = [google_vpc_access_connector.production_connector.ip_cidr_range]
      target_tags   = ["cloud-run-mesh"]  # Tag mesh services if needed
    }
    ```
  - [ ] **Note:** Cloud Run typically doesn't require explicit firewall rules for VPC connector traffic (handled automatically)
  - [ ] Validate by testing connectivity (next subtask)

- [ ] **Validate connectivity** (AC: 8)
  - [ ] **Test gateway → mesh (should succeed):**
    ```bash
    # From gateway Cloud Run instance (via SSH or logs):
    curl https://users-service-internal-xyz.a.run.app/health
    # Should return 200 OK
    ```
  - [ ] **Test public → mesh (should fail):**
    ```bash
    # From local machine:
    curl https://users-service-internal-xyz.a.run.app/health
    # Should return 403 Forbidden or connection refused
    ```
  - [ ] **Test public → gateway (should succeed):**
    ```bash
    # From local machine:
    curl https://gateway-prod-xyz.a.run.app/healthcheck
    # Should return 200 OK
    ```
  - [ ] **Test end-to-end GraphQL query:**
    ```bash
    curl -X POST https://gateway-prod-xyz.a.run.app/graphql \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer [valid-jwt]" \
      -d '{"query": "query { program(id: \"test\") { id_ name } }"}'
    # Should return valid response (gateway successfully reached mesh over VPC)
    ```

## Dev Notes

### Relevant Source Tree
- **OpenTofu Networking:** `infra/networking.tf` (to be created or added to `infra/main.tf`)
- **OpenTofu Service Modules:** `infra/modules/*/main.tf` (all service modules)
- **Gateway Configuration:** `mesh/mesh.config.dynamic.ts` or `mesh/gateway.config.ts`
- **Environment Variables:** `env.production` (service URLs)

### Key Technical Details

**VPC Connector:**
- **Purpose:** Allows Cloud Run services (serverless) to send requests to VPC resources (other Cloud Run services with internal ingress)
- **IP Range:** Must be /28 (16 IPs minimum) and not overlap with existing subnets
- **Cost:** ~$0.0025/hour per instance + data transfer costs (minimal for alpha)
- **Throughput:** Each connector instance handles ~200 Mbps (2 instances = 400 Mbps total)

**Ingress Settings:**
- **`INGRESS_TRAFFIC_ALL`:** Public internet + VPC (default - NOT secure for mesh)
- **`INGRESS_TRAFFIC_INTERNAL_ONLY`:** Only VPC + same project Cloud Run services (SECURE for mesh)
- **`INGRESS_TRAFFIC_INTERNAL_LOAD_BALANCER`:** Only load balancer (not applicable here)

**Service Discovery:**
- Internal Cloud Run URLs remain HTTPS (not http)
- URL format: `https://[service-name]-[hash]-[region].a.run.app`
- Gateway needs to know internal URLs (not public URLs)
- Use environment variables to configure URLs (avoids hardcoding)

**Security Model (after this story):**
```
Internet → Gateway (public, HTTPS)
             ↓ [VPC Connector]
           Mesh services (private, ingress: internal)
```

**users_service Criticality:**
- **Entire system depends on users_service** (auth ID exchange in Story 3.4a)
- If users_service is down, EVERYTHING fails
- Set `min_instances = 1` (no cold starts)
- Monitor health checks closely
- Plan for Kubernetes migration post-alpha (HA with multiple replicas)

### Implementation Notes

**VPC Connector Best Practices:**
- Use `min_instances = 2` for availability (single instance failure doesn't break system)
- Use `max_instances = 3` or higher if expecting high traffic (prevents throttling)
- Use `/28` IP range (16 IPs) - smallest supported size, sufficient for alpha

**Egress Configuration:**
- **`PRIVATE_RANGES_ONLY`:** Only private IPs (10.x, 172.x, 192.168.x) route through VPC (RECOMMENDED)
- **`ALL_TRAFFIC`:** All requests route through VPC (including public internet) - NOT recommended (slower, more costly)
- For this use case: `PRIVATE_RANGES_ONLY` is correct (only mesh services are private)

**Staging vs. Production:**
- Test VPC connector setup in staging FIRST
- Validate connectivity before applying to production
- Keep staging configuration as similar to production as possible (same ingress settings)

**Rollback Plan:**
- If VPC connectivity fails, temporarily change mesh services back to `ingress = "all"` (public)
- This allows system to function while debugging VPC issues
- **DO NOT leave in this state** - public mesh is a security risk

### Security Considerations

**Defense in Depth:**
- VPC isolation is Layer 3/4 security (network level)
- Still need Layer 7 security (application level) - that's Story 3.4a (gateway auth)
- Combine VPC + gateway auth for comprehensive security

**users_service as Single Point of Failure:**
- **Risk:** If users_service is down, entire system fails (auth cannot work)
- **Mitigation (short-term):** `min_instances = 1`, health check monitoring
- **Mitigation (long-term):** Migrate users_service to Kubernetes (HA with 3+ replicas, auto-scaling)

**VPC Connector as Single Point of Failure:**
- **Risk:** If VPC connector fails, gateway cannot reach mesh
- **Mitigation:** `min_instances = 2` (connector has built-in redundancy)
- **Fallback:** Temporarily change mesh services to public ingress (emergency only)

### Testing

**Test file location:** Manual testing via curl + GCP Console validation

**Test standards:**
- Mesh services NOT accessible from public internet
- Gateway CAN reach mesh services over VPC
- Gateway IS accessible from public internet
- End-to-end GraphQL queries succeed

**Testing frameworks:**
- curl commands for HTTP/HTTPS testing
- GCP Console for VPC connector validation
- Gateway logs for connectivity debugging

**Specific testing requirements:**

1. **VPC Connector Validation:**
   ```bash
   # List VPC connectors
   gcloud compute networks vpc-access connectors list --region=us-east1

   # Expected output: mindmirror-prod-connector (READY)
   ```

2. **Ingress Validation (GCP Console):**
   - Navigate to Cloud Run → users_service → Security tab
   - Verify "Ingress: Internal" (not "All")
   - Repeat for all 7 mesh services

3. **Public Access Test (should FAIL):**
   ```bash
   # Attempt to access mesh service from public internet
   curl https://users-service-prod-xyz.a.run.app/health

   # Expected: 403 Forbidden or "Your client does not have permission"
   ```

4. **VPC Access Test (should SUCCEED):**
   ```bash
   # From gateway Cloud Run instance logs (trigger a request that calls users_service):
   # Check logs for successful HTTP 200 response from users_service

   # Or use Cloud Shell (in same project):
   gcloud run services proxy users-service --region=us-east1
   # Then curl localhost:8080/health (should succeed)
   ```

5. **End-to-End GraphQL Test:**
   ```bash
   # Public → Gateway → Mesh (full flow)
   curl -X POST https://gateway-prod-xyz.a.run.app/graphql \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer [valid-jwt]" \
     -d '{
       "query": "query GetUser { user(id: \"test-id\") { id name } }"
     }'

   # Expected: Valid JSON response (proves gateway → users_service works)
   ```

6. **Performance Test (latency):**
   ```bash
   # Measure latency before and after VPC connector
   # Baseline (public mesh): ~50-100ms
   # With VPC connector: ~20-50ms (faster due to VPC routing)

   time curl https://gateway-prod-xyz.a.run.app/graphql -X POST \
     -H "Content-Type: application/json" \
     -d '{"query": "{ __typename }"}'
   ```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-18 | v1.0 | New story: VPC Connector + Private Mesh networking for production security | Alex (DevOps Agent) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_
