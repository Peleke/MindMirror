# =============================================================================
# Cyborg Coach Environment Configuration
# =============================================================================
# Copy this file to .env and update the values

# =============================================================================
# Application Mode Configuration
# =============================================================================
# Set to "demo" for full local functionality, "production" for landing-only
NEXT_PUBLIC_APP_MODE=demo

# =============================================================================
# Supabase Configuration (REQUIRED for authentication)
# =============================================================================
# Create a project at https://supabase.com and get these from Settings â†’ API
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url_here
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# =============================================================================
# OpenAI Configuration (REQUIRED)
# =============================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL database connection
DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/cyborg_coach
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=cyborg_coach

# =============================================================================
# Redis Configuration (for Celery task queue)
# =============================================================================
REDIS_URL=redis://redis:6379/0

# =============================================================================
# Qdrant Vector Database Configuration
# =============================================================================
QDRANT_URL=http://qdrant:6333

# =============================================================================
# API Service Configuration
# =============================================================================
API_PORT=8000
LOG_LEVEL=debug
UVICORN_RELOAD=false

# =============================================================================
# UI Service Configuration
# =============================================================================
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose your LLM provider: "openai" or "ollama"
LLM_PROVIDER=ollama
EMBEDDING_PROVIDER=ollama

# =============================================================================
# Optional: Local LLM Support (Ollama)
# =============================================================================
# If you have Ollama running locally, configure these:
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_CHAT_MODEL=llama3.2

# =============================================================================
# Internal Configuration (Do not modify)
# =============================================================================
# These are used by the Docker containers to detect their environment
I_AM_IN_A_DOCKER_CONTAINER=1

# =============================================================================
# Background Task & Ingestion Configuration
# =============================================================================
# A secret key to protect the re-indexing trigger endpoint
REINDEX_SECRET_KEY=your-super-secret-reindex-key

# -- GCS Emulation Settings --
# Set to "true" to use a local directory for GCS operations, "false" to use a real GCS bucket.
USE_GCS_EMULATOR=true
# When USE_GCS_EMULATOR is "true", this is the local directory to use as the bucket.
# When "false", this must be the name of your actual GCS bucket.
GCS_BUCKET_NAME=local_gcs_bucket

# =============================================================================
# Development vs Production Settings
# =============================================================================

# For production, set to a strong random secret
JWT_SECRET=your-secret-key-here

# For development
DEBUG=true

# =============================================================================
# Optional: External Service Configuration
# =============================================================================

# If using external vector database
# PINECONE_API_KEY=your_pinecone_api_key
# PINECONE_ENVIRONMENT=your_environment

# If using external authentication
# AUTH_PROVIDER_URL=https://your-auth-provider.com
# AUTH_CLIENT_ID=your_client_id
# AUTH_CLIENT_SECRET=your_client_secret

# =============================================================================
# Docker Deployment Notes
# =============================================================================
#
# To deploy with Docker:
# 1. Copy this file to .env: cp env.example .env
# 2. Update OPENAI_API_KEY with your actual key
# 3. Run: docker-compose up --build
#
# Services will be available at:
# - API: http://localhost:8000
# - UI: http://localhost:8501
# - Flower (Celery monitoring): http://localhost:5555
# - PostgreSQL: localhost:5432
# - Redis: localhost:6379
# - Qdrant: http://localhost:6333
#
# For production deployment:
# - Change POSTGRES_PASSWORD to a strong password
# - Set JWT_SECRET to a secure random string
# - Set LOG_LEVEL=info
# - Consider using external managed services for PostgreSQL, Redis, and Qdrant
SUPABASE_ANON_KEY=your-anon-key
